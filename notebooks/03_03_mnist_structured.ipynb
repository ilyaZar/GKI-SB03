{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52d6d878",
   "metadata": {},
   "source": [
    "# Klassifikation von MNIST und Fashion-MNIST\n",
    "In diesem Notebook vergleichen wir verschiedene neuronale Netzarchitekturen zur Klassifikation von Bildern aus dem MNIST- und Fashion-MNIST-Datensatz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e753a209",
   "metadata": {},
   "source": [
    "## Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e995ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d443844",
   "metadata": {},
   "source": [
    "## MNIST-Datensatz laden und vorbereiten\n",
    "\n",
    "- Laden des Fashion-MNIST-Datensatzes aus Keras (10 Klassen, z. B. Schuhe,\n",
    "Pullover, Taschen)\n",
    "- Normalisierung der Bilddaten auf Werte im Bereich [0, 1]\n",
    "- Ursprünglich liegen die Grauwerte im Bereich [0, 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3c64a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = K.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb27bf6",
   "metadata": {},
   "source": [
    "## One-Hot-Encoding der Zielvariablen\n",
    "\n",
    "- One-Hot-Encoding der Zielvariable (10 Klassen -> Vektor mit 10 Einträgen)\n",
    "- Beispiel: Klasse **3** `-> [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ab846",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = K.utils.to_categorical(y_train)\n",
    "y_test = K.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527c1988",
   "metadata": {},
   "source": [
    "## Feedforward-Netzwerk erstellen\n",
    "Ein einfaches Dense-Netz mit zwei Hidden-Layern je 128 Neuronen:\n",
    "\n",
    "- Wieder: sequentieller Aufbau eines FFNN `K.models.Sequential()`\n",
    "- Flatten-Ebene wandelt 2D-Bilder (`28x28`) in 1D-Vektoren (784)\n",
    "- zwei versteckte Dense-Schichten mit jeweils 128 Neuronen, ReLU-Aktivierung\n",
    "- Ausgabeschicht mit 10 Neuronen (für 10 Klassen), Softmax-Aktivierung für\n",
    "Wahrscheinlichkeitsverteilung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb49fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = K.models.Sequential()\n",
    "model.add(K.layers.Flatten())\n",
    "model.add(K.layers.Dense(128, activation='relu'))\n",
    "model.add(K.layers.Dense(128, activation='relu'))\n",
    "model.add(K.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bca354e",
   "metadata": {},
   "source": [
    "## Kompilieren des Modells\n",
    "\n",
    "- Adam-Optimierer\n",
    "- Categorical Crossentropy (für mehrklassige Klassifikation mit One-Hot-Labels)\n",
    "- Accuracy als Metrik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fd29e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c56f7e4",
   "metadata": {},
   "source": [
    "## Training des Feedforward-Netzes\n",
    "\n",
    "- 30 Epochen\n",
    "- Batch-Größe 128\n",
    "- 30 % der Trainingsdaten werden für Validierung verwendet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e44ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=30, batch_size=128, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efef4954",
   "metadata": {},
   "source": [
    "## Hinweise:\n",
    "\n",
    "- Das history-Objekt speichert den gesamten Trainingsverlauf (Loss und Accuracy je Epoche)\n",
    "- Nur dadurch ist es möglich, die Trainings- und Validierungskurven im Nachhinein zu plotten\n",
    "- Die resultierende Grafik zeigt beide Verläufe (Accuracy auf Trainings- und Validierungsdaten)\n",
    "- Bei einfachem MNIST (Ziffern 0–9) erreicht das Netz bereits sehr hohe Genauigkeit\n",
    "- Im Vergleich dazu ist Fashion-MNIST (Kleidungsstücke) komplexer und führt zu geringerer Genauigkeit\n",
    "- Ursache: visuelle Ähnlichkeit mancher Klassen (z. B. Shirt vs. Pullover)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc85bab3",
   "metadata": {},
   "source": [
    "## Trainingsverlauf (Feedforward-Netz)\n",
    "\n",
    "Vergleich im Trainingsdatensatz von sowohl Train- als auch Validationsaccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8398b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Accuracy over epochs')\n",
    "ax.set_xlabel('epochs')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.plot(history.history['accuracy'], label='train')\n",
    "ax.plot(history.history['val_accuracy'], label='validation')\n",
    "ax.legend(loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('../figs/mnist_accuracy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4d7be8",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks (CNN) mit Fashion-MNIST\n",
    "Ziel: Verbesserung der Genauigkeit gegenüber einem einfachen Feedforward-Netz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ffc139",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = K.datasets.fashion_mnist\n",
    "(x_train_mf, y_train_mf), (x_test_mf, y_test_mf) = fashion.load_data()\n",
    "x_train_mf = x_train_mf / 255.0\n",
    "x_test_mf = x_test_mf / 255.0\n",
    "y_train_mf = K.utils.to_categorical(y_train_mf)\n",
    "y_test_mf = K.utils.to_categorical(y_test_mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cef36e1",
   "metadata": {},
   "source": [
    "## CNN-Architektur definieren\n",
    "\n",
    "1. Der erste Layer ist ein Conv2D-Layer:\n",
    "   - `32` Filter mit einer Kerneldimension von `3×3`\n",
    "   - **ReLU**-Aktivierung\n",
    "   - `input_shape=(28, 28, 1)`: Eingabebilder sind `28×28` Pixel mit 1 Kanal (grau)\n",
    "\n",
    "2. Anschließend reduziert ein **MaxPooling2D-Layer* die räumliche Dimension der\n",
    "Featuremaps\n",
    "\n",
    "3. Der **Flatten-Layer** wandelt die 2D-Ausgabe in einen 1D-Vektor um, sodass\n",
    "dieser an vollverbundene (Dense) Schichten übergeben werden kann\n",
    "\n",
    "4. Eine Dense-Schicht mit `100` **Neuronen** und **ReLU-Aktivierung* als Hidden-Layer\n",
    "\n",
    "5. Ausgabeschicht für `10` **Klassen** (z. B. Ziffern oder Kleidungsstücke),\n",
    "**Softmax-Aktivierung** liefert Wahrscheinlichkeiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d44c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(100, activation='relu'))\n",
    "model2.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9f27ad",
   "metadata": {},
   "source": [
    "## Kompilierung des CNN-Modells\n",
    "\n",
    "- Optimierer: `Adam` (effizient, adaptiv)\n",
    "- Verlustfunktion: `categorical_crossentropy` (geeignet für mehrklassige\n",
    "Klassifikation mit One-Hot-Labels)\n",
    "- Metrik: `accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ed58ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062a6422",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mf = x_train_mf.reshape(-1, 28, 28, 1)\n",
    "x_test_mf = x_test_mf.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb01aeb7",
   "metadata": {},
   "source": [
    "## Training des CNNs auf Fashion-MNIST\n",
    "\n",
    "- `x_train_mf` und `y_train_mf`: normalisierte Trainingsbilder und One-Hot-Labels\n",
    "- `x_test_mf` und `y_test_mf`: Testdaten zur Validierung\n",
    "- `30` Epochen, Batch-Größe `128`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d944aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model2.fit(\n",
    "    x_train_mf, y_train_mf,\n",
    "    epochs = 30,\n",
    "    batch_size = 128,\n",
    "    validation_data = (x_test_mf, y_test_mf)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac46df7",
   "metadata": {},
   "source": [
    "## Visualisierung des CNN-Trainingsverlaufs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93ca372",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Accuracy over epochs')\n",
    "ax.set_xlabel('epochs')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.plot(history.history['accuracy'], label='train')\n",
    "ax.plot(history.history['val_accuracy'], label='validation')\n",
    "ax.legend(loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('../figs/mnist_accuracy_convolutional.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a499884b",
   "metadata": {},
   "source": [
    "## Zusammenfassung\n",
    "\n",
    "- Das CNN beginnt mit einem Conv2D-Layer:\n",
    "- Er verwendet 32 Filter mit einer Kernelgröße von 3x3\n",
    "- Diese extrahieren lokale Bildmerkmale (z. B. Kanten, Texturen)\n",
    "- Die erste Zahl (32) gibt die Anzahl der Filter (= Ausgabekanäle) an\n",
    "- Eine höhere Anzahl an Filtern erhöht die Modellkapazität, aber auch den Rechenaufwand\n",
    "\n",
    "In empirischen Tests zeigt sich:\n",
    "- Bereits einfache CNNs erreichen ~99 % Trainingsgenauigkeit und ~91 % Testgenauigkeit\n",
    "- Dies entspricht einem signifikanten Fortschritt gegenüber klassischen Feedforward-Netzen\n",
    "\n",
    "Für eine bessere Generalisierbarkeit wurden zusätzliche Experimente durchgeführt:\n",
    "- Variation der Anzahl der Filter im ersten Conv2D-Layer (z. B. 32, 40, 48, 56)\n",
    "- Das Modell mit 48 Filtern schnitt im Mittel am besten auf den Testdaten ab\n",
    "\n",
    "Eine weitere bewährte Technik zur Vermeidung von Overfitting ist der Einsatz eines Dropout-Layers:\n",
    "- Während des Trainings werden zufällig ausgewählte Neuronen deaktiviert\n",
    "- Dies verhindert eine zu starke Abhängigkeit von einzelnen Aktivierungen\n",
    "- Ziel: bessere Generalisierbarkeit auf unbekannte Daten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c065fa",
   "metadata": {},
   "source": [
    "## CNN mit Dropout zur Vermeidung von Overfitting\n",
    "Ein Dropout-Layer deaktiviert während des Trainings zufällig 10 % der Neuronen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982d1623",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
